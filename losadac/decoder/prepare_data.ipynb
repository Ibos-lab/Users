{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camil\\AppData\\Local\\Temp\\ipykernel_28808\\2939580259.py:13: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "# from preproc_tools import get_fr_by_sample, to_python_hdf5\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from pathlib import Path\n",
    "import h5py\n",
    "from sklearn.svm import SVC\n",
    "from scipy.spatial.distance import pdist\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from ephysvibe.structures.population_data import PopulationData\n",
    "from ephysvibe.structures.neuron_data import NeuronData\n",
    "from ephysvibe.trials import  select_trials\n",
    "from ephysvibe.trials.spikes import firing_rate\n",
    "from typing import Dict, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_number_of_trials(xdict,samples,min_ntr):\n",
    "    for key in samples:\n",
    "        if xdict[key].shape[0]<min_ntr:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_data(fr_samples:Dict,min_ntr:int):\n",
    "    samples = ['11','15','51','55']\n",
    "    enough_tr = check_number_of_trials(fr_samples,samples,min_ntr)\n",
    "    if not enough_tr: return None\n",
    "    c1 = np.concatenate([fr_samples['11'],fr_samples['51']],axis=0)\n",
    "    c5 = np.concatenate([fr_samples['15'],fr_samples['55']],axis=0)\n",
    "    color = {'c1':c1,'c5':c5}\n",
    "    return color\n",
    "\n",
    "def orient_data(fr_samples:Dict,min_ntr:int):\n",
    "    samples = ['11','15','51','55']\n",
    "    enough_tr = check_number_of_trials(fr_samples,samples,min_ntr)\n",
    "    if not enough_tr: return None\n",
    "    o1 = np.concatenate([fr_samples['11'],fr_samples['15']],axis=0)\n",
    "    o5 = np.concatenate([fr_samples['51'],fr_samples['55']],axis=0)\n",
    "    orient = {'o1':o1,'o5':o5}\n",
    "    return orient\n",
    "\n",
    "def sampleid_data(fr_samples:Dict,min_ntr:int):\n",
    "    samples = ['11','15','51','55']\n",
    "    enough_tr = check_number_of_trials(fr_samples,samples,min_ntr)\n",
    "    if not enough_tr: return None\n",
    "    return fr_samples\n",
    "\n",
    "def neutral_data(fr_samples:Dict,min_ntr:int):\n",
    "    samples = ['0','11','15','51','55']\n",
    "    enough_tr = check_number_of_trials(fr_samples,samples,min_ntr)\n",
    "    if not enough_tr: return None\n",
    "    n = fr_samples['0']\n",
    "    nn = np.concatenate([fr_samples['11'],fr_samples['15'],fr_samples['51'],fr_samples['55']],axis=0)\n",
    "    neutral = {'n':n,'nn':nn}\n",
    "    return neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc_for_decoding(neu:NeuronData,params:Dict,to_decode:str,min_ntr:int,start_sample:int,end_sample:int,start_test:int,end_test:int,avgwin:int=100):\n",
    "    # Average fr across time\n",
    "    idx_start_sample = getattr(neu,params['time_before_son'])  + start_sample\n",
    "    idx_end_sample = getattr(neu,params['time_before_son'])  + end_sample\n",
    "    idx_start_test = getattr(neu,params['time_before_t1on']) + start_test\n",
    "    idx_end_test = getattr(neu,params['time_before_t1on']) + end_test\n",
    "    sampleon=getattr(neu,params['sampleon'])\n",
    "    t1on=getattr(neu,params['t1on'])\n",
    "\n",
    "    fr_son = firing_rate.moving_average(\n",
    "            sampleon, win=avgwin, step=1\n",
    "        )[:, idx_start_sample:idx_end_sample]\n",
    "    fr_t1on = firing_rate.moving_average(\n",
    "            t1on, win=avgwin, step=1\n",
    "        )[:, idx_start_test:idx_end_test]\n",
    "\n",
    "    fr = np.concatenate([fr_son,fr_t1on],axis=1)\n",
    "    fr_samples = select_trials.get_sp_by_sample(fr, neu.sample_id[getattr(neu,params['maskson'])])\n",
    "\n",
    "    if to_decode == 'color':\n",
    "        data = color_data(fr_samples,min_ntr)\n",
    "    elif to_decode == 'orient':\n",
    "        data = orient_data(fr_samples,min_ntr)\n",
    "    elif to_decode == 'sampleid':\n",
    "        data = sampleid_data(fr_samples,min_ntr)\n",
    "    elif to_decode == 'neutral':\n",
    "        data = neutral_data(fr_samples,min_ntr)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_train_test_trials(idx_trials, train_ratio):\n",
    "    n_trials = len(idx_trials)\n",
    "    tmp = np.random.permutation(idx_trials)\n",
    "    train = tmp[: int((n_trials * train_ratio))]\n",
    "    test = tmp[int((n_trials * train_ratio)) :]\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_decoding(model,list_data,trial_duration,ntr_train,ntr_test,topred):\n",
    "    test_train_ratio = 1 - ntr_test / ntr_train\n",
    "    ntopred = len(topred)\n",
    "    num_cells=len(list_data)\n",
    "    # Initialize arrays to store train and test data\n",
    "    data_train = np.empty(\n",
    "        [trial_duration, ntr_train*ntopred, num_cells]\n",
    "    )\n",
    "    data_test = np.empty(\n",
    "        [trial_duration, ntr_test*ntopred, num_cells]\n",
    "    )\n",
    "    perf = np.empty([trial_duration, trial_duration])\n",
    "    y_train,y_test = [],[]\n",
    "    for i in range(ntopred):\n",
    "        y_train.append(np.zeros(ntr_train)+i)\n",
    "        y_test.append(np.zeros(ntr_test)+i) \n",
    "    y_train,y_test = np.concatenate(y_train),np.concatenate(y_test)\n",
    "\n",
    "    # Iterate through neurons to randomly pick trials\n",
    "    for icell,cell in enumerate(list_data):\n",
    "        trials_train,trials_test=[],[]\n",
    "        for ipred in topred:\n",
    "            trials = cell[ipred]\n",
    "            idx_trials = np.arange(len(trials))\n",
    "            train, test = pick_train_test_trials(idx_trials, test_train_ratio)\n",
    "            train = np.random.choice(train, ntr_train, replace=True)\n",
    "            test = np.random.choice(test, ntr_test, replace=True)\n",
    "            trials_train.append(trials[train])\n",
    "            trials_test.append(trials[test])\n",
    "\n",
    "        # build matrices of  [timestamp, trials, neurons] dimensions to feed to classifiers\n",
    "        data_train[:, :, icell] = np.concatenate(trials_train,axis=0).T\n",
    "        data_test[:, :, icell] = np.concatenate(trials_test,axis=0).T\n",
    "    \n",
    "    # train and test classifier\n",
    "    for time_train in range(trial_duration):\n",
    "        model.fit(data_train[time_train], y_train)\n",
    "        for time_test in range(trial_duration):\n",
    "            y_predict = model.predict(data_test[time_test])\n",
    "            perf[time_train, time_test] = np.where(y_predict - y_test == 0)[0].shape[0]\n",
    "    \n",
    "    return perf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepeare data for decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 530/530 [00:27<00:00, 19.42it/s]\n"
     ]
    }
   ],
   "source": [
    "# define vars\n",
    "to_decode='color'\n",
    "niterations = 10\n",
    "ntr_train = 30\n",
    "ntr_test = 10\n",
    "min_ntr = 25\n",
    "start_sample=-200\n",
    "end_sample=850\n",
    "start_test=-400\n",
    "end_test=450\n",
    "trial_duration =(end_sample-start_sample)+(end_test-start_test)\n",
    "path=\"\"\n",
    "params= {\n",
    "        'time_before_son': 'time_before_son_in',\n",
    "        'time_before_t1on': 'time_before_t1on_in',\n",
    "        'sampleon': 'sp_son_in',\n",
    "        't1on': 'sp_t1on_in',\n",
    "        'maskson': 'mask_son_in'\n",
    "}\n",
    "# preprocessing \n",
    "popu = PopulationData.from_python_hdf5('test.h5')\n",
    "# split by condition and check enough number of trials (>25)\n",
    "list_data = popu.execute_function(preproc_for_decoding,params,to_decode,min_ntr,start_sample,end_sample,start_test,end_test,avgwin=100,ret_df=False)\n",
    "list_data = [idata for idata in list_data if idata is not None ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 88.29it/s]\n"
     ]
    }
   ],
   "source": [
    "topred=['c1','c5']\n",
    "# pick random trials for training and testing and iterate with a double for to train and test in all t\n",
    "model = SVC(\n",
    "    kernel=\"linear\", C=0.8, decision_function_shape=\"ovr\", gamma=\"auto\", degree=1\n",
    ")\n",
    "all_perf = Parallel(n_jobs=20)(delayed(compute_decoding)(model,list_data,trial_duration,ntr_train,ntr_test,topred) for _ in tqdm(range(niterations)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Users-zKW_FhGB",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
